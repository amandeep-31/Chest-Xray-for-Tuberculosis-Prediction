{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4112e048",
   "metadata": {},
   "source": [
    "Preprocessing....\n",
    "1. Reads images and labels from the Kaggle dataset.\n",
    "2. Creates a stratified subset (10% of the full dataset).\n",
    "3. Splits that subset into train and test sets (90% / 10%).\n",
    "4. Saves them as CSV files in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d474236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset_dir1 = '../Dataset/TB_Chest_Radiography_Database'\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "#function to process the directory\n",
    "def process_directory(directory, label_list, path_list):\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_dir):\n",
    "            for image_name in os.listdir(label_dir):\n",
    "                if image_name.endswith('.jpg') or image_name.endswith('.png'):\n",
    "                    image_path = os.path.join(label_dir, image_name)\n",
    "                    path_list.append(image_path)\n",
    "                    label_list.append(label)\n",
    "\n",
    "process_directory(dataset_dir1, labels, image_paths)\n",
    "data = {'Image_Path': image_paths, 'Label': labels}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the subset size which is 10.00% of the total data\n",
    "subset_size = int(0.1000 * len(df))\n",
    "\n",
    "# Calculate the subset size which is 10.00% of the total data\n",
    "subset_size = int(0.1000 * len(df))\n",
    "\n",
    "# Split the data to get 10.00% of the entire dataset\n",
    "_, subset_df = train_test_split(df, train_size=subset_size, stratify=df['Label'], random_state=42)\n",
    "\n",
    "# Further split the subset into train and validation sets\n",
    "train_df, test_df = train_test_split(subset_df, test_size=0.1, stratify=subset_df['Label'], random_state=42)\n",
    "test_df['Label'] = \"Unknown\"\n",
    "\n",
    "#saving the csv file\n",
    "train_csv_path = '../dataset/train_data.csv'\n",
    "test_csv_path = '../dataset/test_data.csv'\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "test_df.to_csv(test_csv_path, index=False)\n",
    "\n",
    "print(\"CSV files for train and validation data saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Pretrained models\n",
    "from tensorflow.keras.applications import (\n",
    "    Xception,\n",
    "    DenseNet121,\n",
    "    MobileNetV2,\n",
    "    ResNet50V2,\n",
    "    InceptionV3\n",
    ")\n",
    "\n",
    "# Layers, models, optimizers\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Splitting strategy\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau,\n",
    "    ModelCheckpoint\n",
    ")\n",
    "\n",
    "# Additional layers\n",
    "from tensorflow.keras.layers import (\n",
    "    Dropout,\n",
    "    GlobalAveragePooling2D\n",
    ")\n",
    "\n",
    "# Sequential model\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97721c",
   "metadata": {},
   "source": [
    "This section loads the `train_data.csv` file containing the image paths and labels for the TB chest X-ray dataset.  \n",
    "A **stratified train–validation split** is performed to maintain equal class distribution across both sets.\n",
    "\n",
    "Next, data augmentation is applied to the training images to improve model robustness, while validation images are only rescaled.  \n",
    "Finally, two data generators are created to read images from disk, preprocess them to **224×224**, and feed them into the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3730ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv('../dataset/train_data.csv')\n",
    "\n",
    "# Ensure we have 17 unique classes\n",
    "num_classes = len(df['Label'].unique())\n",
    "print(num_classes)\n",
    "\n",
    "# Define the stratified shuffle split\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "\n",
    "# Perform the split\n",
    "for train_index, val_index in split.split(df, df['Label']):\n",
    "    train_df = df.iloc[train_index]\n",
    "    val_df = df.iloc[val_index]\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (224, 224)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    x_col='Image_Path',\n",
    "                                                    y_col='Label',\n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(dataframe=val_df,\n",
    "                                                        x_col='Image_Path',\n",
    "                                                        y_col='Label',\n",
    "                                                        target_size=target_size,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc74ca",
   "metadata": {},
   "source": [
    "Perfroming EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5683891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the dataset\n",
    "print(train_df.head())\n",
    "print(train_df.shape)\n",
    "print(train_df.info())\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2fd87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart for label distribution\n",
    "plt.figure(figsize=(30, 10))\n",
    "sns.countplot(data=train_df, x='Label', order=train_df['Label'].value_counts().index)\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=90)  # Rotate x labels for better readability\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for label distribution\n",
    "plt.figure(figsize=(15, 15))\n",
    "train_df['Label'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Label Distribution')\n",
    "plt.ylabel('')  # Hide the y-label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c18efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique image paths\n",
    "unique_paths = train_df['Image_Path'].nunique()\n",
    "print(f\"Number of unique image paths: {unique_paths}\")\n",
    "\n",
    "# Image paths distribution by label (top 20 paths for readability)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_df, y='Image_Path', hue='Label', order=train_df['Image_Path'].value_counts().index[:20])\n",
    "plt.title('Top 20 Image Paths Distribution by Label')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Image Path')\n",
    "plt.show()\n",
    "\n",
    "# Unique values for each categorical column\n",
    "for column in train_df.select_dtypes(include=['object']).columns:\n",
    "    unique_values = train_df[column].nunique()\n",
    "    print(f\"Column {column} has {unique_values} unique values.\")\n",
    "\n",
    "# Missing values heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(train_df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Heatmap of Missing Values')\n",
    "plt.show()\n",
    "\n",
    "# Label counts summary\n",
    "label_counts = train_df['Label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b983be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "print(train_df.isnull().sum())\n",
    "train_df.fillna(method='ffill', inplace=True)\n",
    "print(train_df.duplicated().sum())\n",
    "train_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4622237a",
   "metadata": {},
   "source": [
    "This function builds a transfer learning–based classification model for chest X-ray images.  \n",
    "A pretrained CNN (e.g., DenseNet121, MobileNetV2, ResNet50V2) is passed as `base_model` and **kept frozen** during initial training to preserve its learned features.\n",
    "\n",
    "On top of the base model, a custom classification head is added:\n",
    "\n",
    "- **GlobalAveragePooling2D** to convert feature maps into a single feature vector  \n",
    "- **Dense(512)** with ReLU activation  \n",
    "- **Dropout(0.5)** to reduce overfitting  \n",
    "- **Dense(256)** with ReLU  \n",
    "- **Dropout(0.5)**  \n",
    "- **Dense(num_classes)** with softmax for final class probabilities  \n",
    "\n",
    "This architecture helps the model learn high-level TB-related patterns while avoiding overfitting on a relatively small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d3ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def create_model(base_model, num_classes):\n",
    "    # Freeze the pretrained backbone initially\n",
    "    base_model.trainable = False  \n",
    "    \n",
    "    # Build the final classification model\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82ac09",
   "metadata": {},
   "source": [
    "This function handles the complete pipeline for training and evaluating a transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ac4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def train_and_evaluate(model, train_data, val_data, model_name, epochs=10):\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "    checkpoint = ModelCheckpoint(filepath=f'{model_name}_best_model.h5',\n",
    "                                monitor='val_loss',\n",
    "                                save_best_only=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=val_data,\n",
    "        steps_per_epoch=len(train_data),\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping, reduce_lr, checkpoint]\n",
    "    )\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_weights(f'{model_name}_best_model.h5')\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    val_loss, val_accuracy = model.evaluate(val_data)\n",
    "    print(f'{model_name} Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Plot accuracy curves\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(f'{model_name} Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    val_data.reset()\n",
    "    Y_pred = model.predict(val_data)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    y_true = val_data.classes\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                display_labels=val_data.class_indices.keys())\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcea19d",
   "metadata": {},
   "source": [
    "This function trains multiple pretrained CNN architectures (e.g., Xception, DenseNet121, MobileNetV2) using the `create_model()` and `train_and_evaluate()` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef56f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(base_models):\n",
    "    # Directory where final (non–best) models are saved\n",
    "    save_dir = 'saved_models'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    histories = {}\n",
    "\n",
    "    # Train and evaluate each base model\n",
    "    for base_model, input_shape, model_name in base_models:\n",
    "        model = create_model(base_model, num_classes)\n",
    "\n",
    "        print(f'Training {model_name}...')\n",
    "        history = train_and_evaluate(model, train_generator, validation_generator, model_name, epochs=10)\n",
    "        histories[model_name] = history\n",
    "\n",
    "        # Save final model again (optional, but allowed)\n",
    "        model.save(os.path.join(save_dir, f'{model_name}_saved.h5'))\n",
    "        print(f'Saved {model_name} model to {save_dir}/{model_name}_saved.h5')\n",
    "\n",
    "    return histories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d01236",
   "metadata": {},
   "source": [
    "Loading the base models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020458d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of base models with their respective input shapes\n",
    "base_models1 = [ #mobilenet base model\n",
    "    (\n",
    "        MobileNetV2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3)\n",
    "        ),\n",
    "        (224, 224, 3),\n",
    "        'MobileNetV2'\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Train using the selected base model\n",
    "model_training(base_models1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05c2b4",
   "metadata": {},
   "source": [
    "# Train InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1970168",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models2 = [\n",
    "    (\n",
    "        InceptionV3(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(299, 299, 3)\n",
    "        ),\n",
    "        (299, 299, 3),\n",
    "        'InceptionV3'\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "model_training(base_models2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79f605",
   "metadata": {},
   "source": [
    "# Train Xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_models3 = [\n",
    "    (\n",
    "        Xception(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(299, 299, 3)\n",
    "        ),\n",
    "        (299, 299, 3),\n",
    "        'Xception'\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "model_training(base_models3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf610d",
   "metadata": {},
   "source": [
    "# Train ResNet50V2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ba208",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models4 = [\n",
    "    (\n",
    "        ResNet50V2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3)\n",
    "        ),\n",
    "        (224, 224, 3),\n",
    "        'ResNet50V2'\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "model_training(base_models4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002c02a",
   "metadata": {},
   "source": [
    "# Train DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe81f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models5 = [\n",
    "    (\n",
    "        DenseNet121(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3)\n",
    "        ),\n",
    "        (224, 224, 3),\n",
    "        'DenseNet121'\n",
    "    )\n",
    "]\n",
    "\n",
    "model_training(base_models5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877dff4e",
   "metadata": {},
   "source": [
    "Testing unlabelled data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "test_df = pd.read_csv('../dataset/test_data.csv')\n",
    "\n",
    "# Load class indices (from train_generator used during training)\n",
    "class_indices_inverse = {v: k for k, v in train_generator.class_indices.items()}\n",
    "\n",
    "# Directory containing the saved models (relative to models/ folder)\n",
    "model_dir = 'saved_models'\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Function to process images in batches\n",
    "def process_images_in_batches(image_paths, model, target_size, batch_size):\n",
    "    num_images = len(image_paths)\n",
    "    num_batches = (num_images + batch_size - 1) // batch_size  # number of batches\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, num_images)\n",
    "        batch_paths = image_paths[start_idx:end_idx]\n",
    "\n",
    "        batch_images = []\n",
    "        for img_path in batch_paths:\n",
    "            img = image.load_img(img_path, target_size=target_size)\n",
    "            img = image.img_to_array(img)\n",
    "            img = img / 255.0\n",
    "            batch_images.append(img)\n",
    "\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_predictions_probs = model.predict(batch_images)\n",
    "        batch_predictions = np.argmax(batch_predictions_probs, axis=1)\n",
    "\n",
    "        all_predictions.extend(batch_predictions)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "# Iterate over each model file in the saved_models directory\n",
    "for model_file in os.listdir(model_dir):\n",
    "    if model_file.endswith('.h5'):\n",
    "        # Load the model\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # Determine target size based on model name\n",
    "        if \"Xception_saved\" in model_file or \"InceptionV3_saved\" in model_file:\n",
    "            target_size = (299, 299)\n",
    "        else:\n",
    "            target_size = (224, 224)\n",
    "\n",
    "        # Process images in batches and make predictions\n",
    "        image_paths = test_df['Image_Path'].tolist()\n",
    "        prediction = process_images_in_batches(image_paths, model, target_size, batch_size)\n",
    "\n",
    "        # Map predictions to class labels\n",
    "        prediction_labels = [class_indices_inverse[label] for label in prediction]\n",
    "\n",
    "        # Create a DataFrame with predictions\n",
    "        predicted_df = pd.DataFrame({\n",
    "            'Image_Path': test_df['Image_Path'],\n",
    "            'Label': prediction_labels,\n",
    "        })\n",
    "\n",
    "        # Save predictions to CSV in saved_models/ folder\n",
    "        csv_path = os.path.join(model_dir, f'predicted_{model_file.split(\".\")[0]}.csv')\n",
    "        predicted_df.to_csv(csv_path, header=True, index=False)\n",
    "\n",
    "        print(f\"Predictions saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6586695",
   "metadata": {},
   "source": [
    "Image label prediction and visualization (the image has been showcased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd294b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "filenames = [\n",
    "    '../dataset/TB_Chest_Radiography_Database/Normal/Normal-1157.png',\n",
    "    '../dataset/TB_Chest_Radiography_Database/Tuberculosis/Tuberculosis-499.png',\n",
    "    '../dataset/TB_Chest_Radiography_Database/Normal/Normal-1922.png',\n",
    "    '../dataset/TB_Chest_Radiography_Database/Tuberculosis/Tuberculosis-539.png'\n",
    "]\n",
    "\n",
    "def load_predicted_labels(csv_file_path):\n",
    "    predicted_labels = {}\n",
    "    with open(csv_file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            predicted_labels[row['Image_Path']] = row['Label']\n",
    "    return predicted_labels\n",
    "\n",
    "def visualize_predictions(filenames, predicted_labels):\n",
    "    for filename in filenames:\n",
    "        img = image.load_img(filename, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_processed = img_array / 255.0  # Normalize the image\n",
    "\n",
    "        # Check if the filename is in predicted_labels\n",
    "        if filename in predicted_labels:\n",
    "            predicted_class_name = predicted_labels[filename]\n",
    "        else:\n",
    "            print(f\"Filename not found: {filename}\")\n",
    "            predicted_class_name = \"Unknown\"\n",
    "\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(img_processed.astype(\"float32\"))  # Display the processed image\n",
    "        plt.title(f\"Prediction - {predicted_class_name}\", size=12, color='red')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Directory containing the predicted CSV files (inside models/)\n",
    "csv_dir = 'saved_models'\n",
    "\n",
    "# Iterate over each CSV file in the directory\n",
    "for csv_file in os.listdir(csv_dir):\n",
    "    if csv_file.startswith('predicted_') and csv_file.endswith('.csv'):\n",
    "        # Determine the model name\n",
    "        model_name = csv_file.split('.')[0]\n",
    "\n",
    "        # Path to the CSV file containing predictions for the current model\n",
    "        predicted_csv_file = os.path.join(csv_dir, csv_file)\n",
    "\n",
    "        # Load predicted labels from the CSV file\n",
    "        predicted_labels = load_predicted_labels(predicted_csv_file)\n",
    "\n",
    "        # Predict and plot images using predicted labels\n",
    "        print(f\"Predictions using: {model_name}\")\n",
    "        visualize_predictions(filenames, predicted_labels)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
